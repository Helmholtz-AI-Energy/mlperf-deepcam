{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global parameters\n",
    "cudadir = \"/usr/common/software/cuda/10.2.89\"\n",
    "homedir = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and output dirs\n",
    "#datadirs = [\"../scripts/tf_cnn_kernels_nsight/runs/386219\"]\n",
    "#datadirs = [\"../scripts/tf_cnn_kernels_nsight/runs/386058\"]\n",
    "#datadirs = os.path.join(homedir,\"data/tf_2.0b/new_nsight\")\n",
    "datadirs = [\"../data/pytorch_1.5\"]\n",
    "outputdir = \"../results/pytorch_1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_frame(df_metrics):\n",
    "    #Copy the profile frame to make sure not to overwrite it and potentially read it in again if we screwed it up\n",
    "    selectkeys = [\"Precision\", \"Network Name\", \"Batch Size\", \"Pass\", \"Name\"]\n",
    "    \n",
    "    tc_peak_perf_flops = 125*10**12\n",
    "\n",
    "    #as metricdf use df_summary\n",
    "    metricdf = df_metrics.copy()\n",
    "    metricdf.sort_values(by=selectkeys,inplace=True)\n",
    "    metricdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    ####### Get timing information\n",
    "\n",
    "    ### CUDA Time\n",
    "    cudatimedf = metricdf[ (metricdf[\"Metric Name\"].str.contains(\"smsp__cycles_elapsed\")) ].sort_values(selectkeys)\n",
    "    # get cycles and rates\n",
    "    cyclesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"smsp__cycles_elapsed\") & (metricdf[\"Metric Type\"]==\"total\"), selectkeys+[\"Metric Value\"]]\n",
    "    ratesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"smsp__cycles_elapsed\") & (metricdf[\"Metric Type\"]==\"rate\"), selectkeys+[\"Metric Value\"]]\n",
    "    \n",
    "    # combine\n",
    "    cudatimedf = cyclesdf.merge(ratesdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    cudatimedf[\"CUDA Time Avg\"] = cudatimedf[\"Metric Value_x\"] / (cudatimedf[\"Metric Value_y\"] * 1e9)\n",
    "    cudatimedf = cudatimedf.fillna(0.)\n",
    "    # merge into results\n",
    "    metricdf = metricdf.merge(cudatimedf[selectkeys+[\"CUDA Time Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    ### Tensor Core Time\n",
    "    tctimedf = metricdf[ (metricdf[\"Metric Name\"].str.contains(\"smsp__pipe_tensor_op_hmma_cycles_active\")) ].sort_values(selectkeys)\n",
    "    # get cycles and rates\n",
    "    cyclesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"smsp__pipe_tensor_op_hmma_cycles_active\") & (metricdf[\"Metric Type\"]==\"total\"), selectkeys+[\"Metric Value\"]]\n",
    "    ratesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"smsp__pipe_tensor_op_hmma_cycles_active\") & (metricdf[\"Metric Type\"]==\"rate\"), selectkeys+[\"Metric Value\"]]\n",
    "    \n",
    "    # combine\n",
    "    tctimedf = cyclesdf.merge(ratesdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    tctimedf[\"TC Time Avg\"] = tctimedf[\"Metric Value_x\"] / (tctimedf[\"Metric Value_y\"] * 1e9).fillna(0.)\n",
    "    tctimedf = tctimedf.fillna(0.)\n",
    "    metricdf = metricdf.merge(tctimedf[selectkeys+[\"TC Time Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    ### check\n",
    "    #tmpdf = metricdf.loc[(abs(metricdf[\"CUDA Time Avg\"] - metricdf[\"TC Time Avg\"])/metricdf[\"CUDA Time Avg\"] > 0.01) & (metricdf[\"TC Time Avg\"] != 0)]\n",
    "    #if not tmpdf.empty:\n",
    "    #    print(tmpdf)\n",
    "    #    raise ValueError(\"CUDA Time not consistent wit TC Time\")    \n",
    "        \n",
    "        \n",
    "    ####### Get number of FLOPs\n",
    "    \n",
    "    ### FMA FLOPs = number of FMA instructions x 2\n",
    "    metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"fma\"), [\"Metric Value\"]] *= 2\n",
    "    \n",
    "\n",
    "    ### FP64 FLOPs\n",
    "    #metrics = ['smsp__sass_thread_inst_executed_op_dadd_pred_on',\n",
    "    #           'smsp__sass_thread_inst_executed_op_dfma_pred_on',\n",
    "    #           'smsp__sass_thread_inst_executed_op_dmul_pred_on']\n",
    "    #tmpdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    #tmpdf = tmpdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"FP64 FLOPs\"})\n",
    "    #metricdf = metricdf.merge(tmpdf[selectkeys+[\"FP64 FLOPs\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### FP32 FLOPs\n",
    "    metrics = ['smsp__sass_thread_inst_executed_op_fadd_pred_on',\n",
    "               'smsp__sass_thread_inst_executed_op_ffma_pred_on',\n",
    "               'smsp__sass_thread_inst_executed_op_fmul_pred_on']\n",
    "    tmpdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    tmpdf = tmpdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"FP32 FLOPs Avg\"})\n",
    "    metricdf = metricdf.merge(tmpdf[selectkeys+[\"FP32 FLOPs Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    ### FP16 FLOPs\n",
    "    metrics = ['smsp__sass_thread_inst_executed_op_hadd_pred_on',\n",
    "               'smsp__sass_thread_inst_executed_op_hfma_pred_on',\n",
    "               'smsp__sass_thread_inst_executed_op_hmul_pred_on']\n",
    "    tmpdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    tmpdf = tmpdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"FP16 FLOPs Avg\"})\n",
    "    metricdf = metricdf.merge(tmpdf[selectkeys+[\"FP16 FLOPs Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    #### TC FLOPs\n",
    "    tmpdf = metricdf.loc[ metricdf[\"Metric Name\"] == \"sm__inst_executed_pipe_tensor_op_hmma\", selectkeys+[\"TC Time Avg\", \"Metric Value\"] ].copy()\n",
    "    tmpdf[\"Utilization\"] = 0.01 * tmpdf[\"Metric Value\"]\n",
    "    tmpdf[\"TC FLOPs Avg\"] = tc_peak_perf_flops * tmpdf[\"Utilization\"] * tmpdf[\"TC Time Avg\"]\n",
    "    metricdf = metricdf.merge(tmpdf[selectkeys+[\"TC FLOPs Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    \n",
    "    ### Total FLOPs\n",
    "    metricdf[\"FLOPs Avg\"] = metricdf[\"FP32 FLOPs Avg\"] + metricdf[\"FP16 FLOPs Avg\"] + metricdf[\"TC FLOPs Avg\"] #+ metricdf[\"FP64 FLOPs\"]\n",
    "    \n",
    "    \n",
    "    ### FLOPs fractions\n",
    "    #metricdf[\"FP64 FLOPs Fraction\"] = metricdf[\"FP64 FLOPs\"]/metricdf[\"FLOPs\"]\n",
    "    metricdf[\"FP32 FLOPs Fraction Avg\"] = metricdf[\"FP32 FLOPs Avg\"]/metricdf[\"FLOPs Avg\"]\n",
    "    metricdf[\"FP16 FLOPs Fraction Avg\"] = metricdf[\"FP16 FLOPs Avg\"]/metricdf[\"FLOPs Avg\"]\n",
    "    metricdf[\"TC FLOPs Fraction Avg\"]   = metricdf[\"TC FLOPs Avg\"]/metricdf[\"FLOPs Avg\"]\n",
    "    \n",
    "    ####### Get number of bytes\n",
    "    \n",
    "    ### Shared transactions\n",
    "    #project out\n",
    "    shareddf = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"l1tex__data_pipe_lsu_wavefronts_mem_shared_op\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    shareddf = shareddf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"Shared Transactions Avg\"})\n",
    "    #add to timings\n",
    "    metricdf = metricdf.merge(shareddf[selectkeys+[\"Shared Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    \n",
    "    ### L1 atomic transactions\n",
    "    # project out\n",
    "    metrics = ['l1tex__t_set_accesses_pipe_lsu_mem_global_op_atom',\n",
    "               'l1tex__t_set_accesses_pipe_lsu_mem_global_op_red',\n",
    "               'l1tex__t_set_accesses_pipe_tex_mem_surface_op_atom',\n",
    "               'l1tex__t_set_accesses_pipe_tex_mem_surface_op_red']\n",
    "    atomicdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    # get reads and writes\n",
    "    atomicdf = atomicdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"L1 Atomic Transactions Avg\"})\n",
    "    # add to timings\n",
    "    metricdf = metricdf.merge(atomicdf[selectkeys+[\"L1 Atomic Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### Local transactions \n",
    "    # project out\n",
    "    localdf = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"l1tex__t_sectors_pipe_lsu_mem_local_op\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    localdf = localdf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"Local Transactions Avg\"})\n",
    "    # add to timings\n",
    "    metricdf = metricdf.merge(localdf[selectkeys+[\"Local Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### Global transactions \n",
    "    # project out\n",
    "    globaldf = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"l1tex__t_sectors_pipe_lsu_mem_global_op\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    globaldf = globaldf.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"Global Transactions Avg\"})\n",
    "    # add to timings\n",
    "    metricdf = metricdf.merge(globaldf[selectkeys+[\"Global Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### L1 Bytes\n",
    "    metricdf[\"L1 Transactions Avg\"] = (metricdf[\"Shared Transactions Avg\"] + metricdf[\"L1 Atomic Transactions Avg\"]\n",
    "                            + metricdf[\"Local Transactions Avg\"] + metricdf[\"Global Transactions Avg\"])\n",
    "    metricdf[\"L1 Bytes Avg\"] = metricdf[\"L1 Transactions Avg\"] * 32\n",
    "    \n",
    "    \n",
    "    ### L2 atomic & reduction\n",
    "    metricdf.loc[(metricdf[\"Metric Name\"].str.contains(\"lts__t_sectors_op\")) & (metricdf[\"Metric Type\"]==\"total\"), [\"Metric Value\"]] *= 2\n",
    "\n",
    "    \n",
    "    ### L2 transactions\n",
    "    # project out\n",
    "    l2df = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"lts__t_sectors_op\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    l2df = l2df.groupby(selectkeys).sum().reset_index().rename(columns={\"Metric Value\": \"L2 Transactions Avg\"})\n",
    "    l2df[\"L2 Bytes Avg\"] = l2df[\"L2 Transactions Avg\"] * 32\n",
    "    # add to timings\n",
    "    metricdf = metricdf.merge(l2df[selectkeys+[\"L2 Transactions Avg\", \"L2 Bytes Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### DRAM Bytes\n",
    "    # project out\n",
    "    dramdf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"dram__sectors\") ].sort_values(selectkeys)\n",
    "    # get reads and writes\n",
    "    dramreadsdf = dramdf.loc[(dramdf[\"Metric Name\"]==\"dram__sectors\") & (dramdf[\"Metric Type\"]==\"read\"), selectkeys+[\"Metric Value\"]]\n",
    "    dramwritesdf = dramdf.loc[(dramdf[\"Metric Name\"]==\"dram__sectors\") & (dramdf[\"Metric Type\"]==\"write\"), selectkeys+[\"Metric Value\"]]\n",
    "    # combine\n",
    "    dramdf = dramwritesdf.merge(dramreadsdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    dramdf[\"DRAM Transactions Avg\"] = dramdf[\"Metric Value_x\"] + dramdf[\"Metric Value_y\"]\n",
    "    dramdf[\"DRAM Bytes Avg\"] = dramdf[\"DRAM Transactions Avg\"] * 32\n",
    "    #print(dramdf[['Name', 'Metric Value_x', 'Metric Value_y']])\n",
    "    metricdf = metricdf.merge(dramdf[selectkeys+[\"DRAM Transactions Avg\", \"DRAM Bytes Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    \n",
    "    ### Host Memory Bytes\n",
    "    # project out\n",
    "    sysmemdf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"lts__t_sectors_aperture_sysmem_op\") ].sort_values(selectkeys)\n",
    "    # get reads and writes\n",
    "    sysmemreadsdf = sysmemdf.loc[(sysmemdf[\"Metric Name\"]==\"lts__t_sectors_aperture_sysmem_op\") & (sysmemdf[\"Metric Type\"]==\"read\"), selectkeys+[\"Metric Value\"]]\n",
    "    sysmemwritesdf = sysmemdf.loc[(sysmemdf[\"Metric Name\"]==\"lts__t_sectors_aperture_sysmem_op\") & (sysmemdf[\"Metric Type\"]==\"write\"), selectkeys+[\"Metric Value\"]]\n",
    "    # combine\n",
    "    sysmemdf = sysmemwritesdf.merge(sysmemreadsdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    sysmemdf[\"SYSMEM Transactions Avg\"] = sysmemdf[\"Metric Value_x\"] + sysmemdf[\"Metric Value_y\"]\n",
    "    sysmemdf[\"SYSMEM Bytes Avg\"] = sysmemdf[\"SYSMEM Transactions Avg\"] * 32\n",
    "    #print(dramdf[['Name', 'Metric Value_x', 'Metric Value_y']])\n",
    "    metricdf = metricdf.merge(sysmemdf[selectkeys+[\"SYSMEM Transactions Avg\", \"SYSMEM Bytes Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    ####### Clean up and return:\n",
    "    del metricdf[\"Metric Value\"]\n",
    "    del metricdf[\"Metric Name\"]\n",
    "    del metricdf[\"Metric Type\"]\n",
    "    #del metricdf[\"Invocations\"]\n",
    "    metricdf.drop_duplicates(keep = 'first', inplace = True)\n",
    "    \n",
    "\n",
    "    ### Get performance\n",
    "    metricdf[\"Performance GFlop/s\"]      = metricdf[\"FLOPs Avg\"]      / (metricdf[\"CUDA Time Avg\"]*10**9)\n",
    "    metricdf[\"FP32 Performance GFlop/s\"] = metricdf[\"FP32 FLOPs Avg\"] / (metricdf[\"CUDA Time Avg\"]*10**9)\n",
    "    metricdf[\"FP16 Performance GFlop/s\"] = metricdf[\"FP16 FLOPs Avg\"] / (metricdf[\"CUDA Time Avg\"]*10**9)\n",
    "    metricdf[\"TC Performance GFlop/s\"]   = metricdf[\"TC FLOPs Avg\"]   / (metricdf[\"TC Time Avg\"]*10**9)\n",
    "\n",
    "    \n",
    "    ### Get AI\n",
    "    # L1\n",
    "    metricdf[\"L1 AI\"]        = metricdf[\"FLOPs Avg\"]      / metricdf[\"L1 Bytes Avg\"]\n",
    "    metricdf[\"FP32 L1 AI\"]   = metricdf[\"FP32 FLOPs Avg\"] / metricdf[\"L1 Bytes Avg\"]\n",
    "    metricdf[\"FP16 L1 AI\"]   = metricdf[\"FP16 FLOPs Avg\"] / metricdf[\"L1 Bytes Avg\"]\n",
    "    metricdf[\"TC L1 AI\"]     = metricdf[\"TC FLOPs Avg\"]   / metricdf[\"L1 Bytes Avg\"]\n",
    "    # L2\n",
    "    metricdf[\"L2 AI\"]        = metricdf[\"FLOPs Avg\"]      / metricdf[\"L2 Bytes Avg\"]\n",
    "    metricdf[\"FP32 L2 AI\"]   = metricdf[\"FP32 FLOPs Avg\"] / metricdf[\"L2 Bytes Avg\"]\n",
    "    metricdf[\"FP16 L2 AI\"]   = metricdf[\"FP16 FLOPs Avg\"] / metricdf[\"L2 Bytes Avg\"]\n",
    "    metricdf[\"TC L2 AI\"]     = metricdf[\"TC FLOPs Avg\"]   / metricdf[\"L2 Bytes Avg\"]\n",
    "    # DRAM\n",
    "    metricdf[\"DRAM AI\"]      = metricdf[\"FLOPs Avg\"]      / metricdf[\"DRAM Bytes Avg\"]\n",
    "    metricdf[\"FP32 DRAM AI\"] = metricdf[\"FP32 FLOPs Avg\"] / metricdf[\"DRAM Bytes Avg\"]\n",
    "    metricdf[\"FP16 DRAM AI\"] = metricdf[\"FP16 FLOPs Avg\"] / metricdf[\"DRAM Bytes Avg\"]\n",
    "    metricdf[\"TC DRAM AI\"]   = metricdf[\"TC FLOPs Avg\"]   / metricdf[\"DRAM Bytes Avg\"]\n",
    "    # SYSMEM\n",
    "    metricdf[\"SYSMEM AI\"]      = metricdf[\"FLOPs Avg\"]      / metricdf[\"SYSMEM Bytes Avg\"]\n",
    "    metricdf[\"FP32 SYSMEM AI\"] = metricdf[\"FP32 FLOPs Avg\"] / metricdf[\"SYSMEM Bytes Avg\"]\n",
    "    metricdf[\"FP16 SYSMEM AI\"] = metricdf[\"FP16 FLOPs Avg\"] / metricdf[\"SYSMEM Bytes Avg\"]\n",
    "    metricdf[\"TC SYSMEM AI\"]   = metricdf[\"TC FLOPs Avg\"]   / metricdf[\"SYSMEM Bytes Avg\"]\n",
    "\n",
    "    ### Cleanup\n",
    "    metricdf.sort_values(by=selectkeys).reset_index(drop=True, inplace=True)\n",
    "    #print(metricdf[['CUDA Time Avg', 'TC Time Avg']])\n",
    "    \n",
    "    return metricdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the files\n",
    "files = []\n",
    "for datadir in datadirs:\n",
    "    files += [ os.path.join(datadir,x) for x in os.listdir(datadir) if ((os.path.splitext(x)[-1] == \".ncu-rep\"))]\n",
    "\n",
    "#recs\n",
    "records = []\n",
    "\n",
    "#build feature list:\n",
    "for path in files:\n",
    "    \n",
    "    #filename\n",
    "    file = os.path.basename(path)\n",
    "    \n",
    "    #path\n",
    "    path = os.path.dirname(path)\n",
    "    \n",
    "    #splitup\n",
    "    splt = file.split(\".\")\n",
    "    \n",
    "    prefix = \".\".join(splt[0:-1])\n",
    "    \n",
    "    #append to records\n",
    "    records.append({\"prefix\": prefix, \"file\": os.path.join(path, file)})\n",
    "\n",
    "#put in df\n",
    "recorddf = pd.DataFrame(records).sort_values([\"prefix\"])\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_dram__sectors_read.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_dram__sectors_write.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__t_sectors_pipe_lsu_mem_local_op_ld.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__t_sectors_pipe_lsu_mem_local_op_st.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__t_set_accesses_pipe_lsu_mem_global_op_atom.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__t_set_accesses_pipe_lsu_mem_global_op_red.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__t_set_accesses_pipe_tex_mem_surface_op_atom.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_l1tex__t_set_accesses_pipe_tex_mem_surface_op_red.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_lts__t_sectors_aperture_sysmem_op_read.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_lts__t_sectors_aperture_sysmem_op_write.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_lts__t_sectors_op_atom.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_lts__t_sectors_op_read.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_lts__t_sectors_op_red.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_lts__t_sectors_op_write.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_sm__inst_executed_pipe_tensor_op_hmma.avg.pct_of_peak_sustained_active.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__cycles_elapsed.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__cycles_elapsed.sum.per_second.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__inst_executed_pipe_tensor_op_hmma.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__pipe_tensor_op_hmma_cycles_active.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__pipe_tensor_op_hmma_cycles_active.sum.per_second.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_fadd_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_ffma_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_fmul_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_hadd_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_hfma_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_backward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_hmul_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_dram__sectors_read.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_dram__sectors_write.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__t_sectors_pipe_lsu_mem_local_op_ld.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__t_sectors_pipe_lsu_mem_local_op_st.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__t_set_accesses_pipe_lsu_mem_global_op_atom.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__t_set_accesses_pipe_lsu_mem_global_op_red.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__t_set_accesses_pipe_tex_mem_surface_op_atom.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_l1tex__t_set_accesses_pipe_tex_mem_surface_op_red.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_lts__t_sectors_aperture_sysmem_op_read.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_lts__t_sectors_aperture_sysmem_op_write.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_lts__t_sectors_op_atom.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_lts__t_sectors_op_read.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_lts__t_sectors_op_red.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_lts__t_sectors_op_write.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_sm__inst_executed_pipe_tensor_op_hmma.avg.pct_of_peak_sustained_active.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__cycles_elapsed.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__cycles_elapsed.sum.per_second.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__inst_executed_pipe_tensor_op_hmma.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__pipe_tensor_op_hmma_cycles_active.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__pipe_tensor_op_hmma_cycles_active.sum.per_second.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_fadd_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_ffma_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_fmul_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_hadd_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_hfma_pred_on.sum.ncu-rep\n",
      "../data/pytorch_1.5/profile.pass_forward.batchsize_2.metric_smsp__sass_thread_inst_executed_op_hmul_pred_on.sum.ncu-rep\n"
     ]
    }
   ],
   "source": [
    "#sort by those keys:\n",
    "sortkeys = [\"Network Name\", \\\n",
    "            \"Batch Size\", \"Pass\", \\\n",
    "            \"Precision\", \"Device\", \"Name\"]\n",
    "    \n",
    "#group by prefixes and files\n",
    "all_prefixes = set([x.split(\".pass\")[0] for x in recorddf[\"prefix\"]])\n",
    "all_passes = set([re.match(r'.*\\.pass_(.*?)\\.', x).groups()[0] for x in recorddf[\"prefix\"].unique()])\n",
    "\n",
    "#metrics\n",
    "df_profiles = []\n",
    "\n",
    "for pref in all_prefixes:\n",
    "    \n",
    "    #set empty lists\n",
    "    df_times = []\n",
    "    df_timeline = []\n",
    "    df_summary = []\n",
    "    \n",
    "    #print prefix\n",
    "    #print(pref)\n",
    "    \n",
    "    #loop over passes\n",
    "    df_times = []\n",
    "    df_metrics = []\n",
    "    for pas in all_passes:\n",
    "        \n",
    "        #project frame\n",
    "        files = recorddf.loc[recorddf[\"prefix\"].apply(lambda x: re.match(r'.*\\.pass_(.*?)\\.', x).groups()[0]) == pas, \"file\"].values\n",
    "        \n",
    "        #project the invididual files\n",
    "        metricfiles = [x for x in files if x.endswith(\".ncu-rep\")]\n",
    "        \n",
    "        for metricfile in metricfiles:\n",
    "            \n",
    "            #print the file\n",
    "            print(metricfile)\n",
    "            \n",
    "            #get the parameters from the filename\n",
    "            parameters = parse_filename_nsight(os.path.basename(metricfile))\n",
    "        \n",
    "            #metrics\n",
    "            metricdf = import_nsight_metric(metricfile, cuda_dir=cudadir)\n",
    "            for key in parameters:\n",
    "                metricdf[key] = parameters[key]\n",
    "        \n",
    "            #fuse read/write metrics together:\n",
    "            unique_metrics = metricdf[\"Metric Name\"].unique()\n",
    "            unique_metrics = set([x.split(\".\")[0].replace(\"_write\",\"\").replace(\"_read\",\"\").replace(\"_ld\",\"\").replace(\"_st\",\"\") for x in unique_metrics])\n",
    "            #add the metric type\n",
    "            metricdf[\"Metric Type\"] = \"total\"\n",
    "            #read\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\"_read\"), \"Metric Type\" ] = \"read\"\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\"_ld\"), \"Metric Type\" ] = \"read\"\n",
    "            #write\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\"_write\"), \"Metric Type\" ] = \"write\"\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\"_st\"), \"Metric Type\" ] = \"write\"\n",
    "            #rate\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\".per_second\"), \"Metric Type\" ] = \"rate\"\n",
    "        \n",
    "            for metric in unique_metrics:\n",
    "                metricdf.loc[ metricdf[ \"Metric Name\"].str.startswith(metric), \"Metric Name\" ] = metric\n",
    "\n",
    "            #append to DF:\n",
    "            df_metrics.append(metricdf)\n",
    "    \n",
    "    #concat the frames\n",
    "    metricdf = pd.concat(df_metrics).reset_index(drop=True)\n",
    "    \n",
    "    #compute the profile\n",
    "    profiledf = transpose_frame(metricdf)\n",
    "    df_profiles.append(profiledf)\n",
    "\n",
    "#concat everything\n",
    "profiledf = pd.concat(df_profiles).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Invocations</th>\n",
       "      <th>Network Name</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Pass</th>\n",
       "      <th>Precision</th>\n",
       "      <th>CUDA Time Avg</th>\n",
       "      <th>TC Time Avg</th>\n",
       "      <th>FP32 FLOPs Avg</th>\n",
       "      <th>FP16 FLOPs Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>FP16 L2 AI</th>\n",
       "      <th>TC L2 AI</th>\n",
       "      <th>DRAM AI</th>\n",
       "      <th>FP32 DRAM AI</th>\n",
       "      <th>FP16 DRAM AI</th>\n",
       "      <th>TC DRAM AI</th>\n",
       "      <th>SYSMEM AI</th>\n",
       "      <th>FP32 SYSMEM AI</th>\n",
       "      <th>FP16 SYSMEM AI</th>\n",
       "      <th>TC SYSMEM AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_128x1...</td>\n",
       "      <td>384.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>backward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>3.382784e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.269259</td>\n",
       "      <td>460.004408</td>\n",
       "      <td>0.110112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>459.894296</td>\n",
       "      <td>6.308905e+07</td>\n",
       "      <td>1.510171e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.307394e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_128x1...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>backward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>2.048000e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>175.980559</td>\n",
       "      <td>411.945348</td>\n",
       "      <td>0.117225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>411.828123</td>\n",
       "      <td>3.212944e+07</td>\n",
       "      <td>9.142857e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.212029e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_128x1...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>backward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>6.930432e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>421.062825</td>\n",
       "      <td>1362.422104</td>\n",
       "      <td>0.056049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1362.366055</td>\n",
       "      <td>7.520624e+08</td>\n",
       "      <td>3.093943e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.520315e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_128x2...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>backward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>3.538944e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.586092</td>\n",
       "      <td>1491.376331</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1491.355488</td>\n",
       "      <td>1.130491e+09</td>\n",
       "      <td>1.579886e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.130475e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_64x32...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>backward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>2.347008e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.525030</td>\n",
       "      <td>70.019151</td>\n",
       "      <td>0.017258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.001893</td>\n",
       "      <td>4.251066e+07</td>\n",
       "      <td>1.047771e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.250018e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>volta_fp16_s884cudnn_fp16_256x64_ldg8_relu_f2f...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>forward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1.061683e+07</td>\n",
       "      <td>663552.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>63.149830</td>\n",
       "      <td>262.910613</td>\n",
       "      <td>0.698876</td>\n",
       "      <td>0.043680</td>\n",
       "      <td>262.168057</td>\n",
       "      <td>1.783014e+07</td>\n",
       "      <td>4.739657e+04</td>\n",
       "      <td>2962.285714</td>\n",
       "      <td>1.777978e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>volta_fp16_s884cudnn_fp16_256x64_ldg8_relu_f2f...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>forward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>5.662310e+07</td>\n",
       "      <td>3538944.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>57.673099</td>\n",
       "      <td>234.258467</td>\n",
       "      <td>0.665453</td>\n",
       "      <td>0.041591</td>\n",
       "      <td>233.551423</td>\n",
       "      <td>8.898636e+07</td>\n",
       "      <td>2.527817e+05</td>\n",
       "      <td>15798.857143</td>\n",
       "      <td>8.871778e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>volta_fp16_s884gemm_fp16_128x128_ldg8_f2f_nt</td>\n",
       "      <td>36.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>forward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>5.573837e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.365833</td>\n",
       "      <td>246.901319</td>\n",
       "      <td>0.387155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.514164</td>\n",
       "      <td>1.586883e+08</td>\n",
       "      <td>2.488320e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.584394e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>volta_fp16_scudnn_fp16_128x64_relu_interior_nn_v1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>forward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.833173e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.543450</td>\n",
       "      <td>30.543450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.183808e+06</td>\n",
       "      <td>8.183808e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>volta_fp16_sgemm_fp16_128x32_nt</td>\n",
       "      <td>12.0</td>\n",
       "      <td>deepCam</td>\n",
       "      <td>2</td>\n",
       "      <td>forward</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.630957e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.308326</td>\n",
       "      <td>29.308326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.620963e+07</td>\n",
       "      <td>1.620963e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name  Invocations  \\\n",
       "0    Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_128x1...        384.0   \n",
       "1    Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_128x1...         12.0   \n",
       "2    Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_128x1...          6.0   \n",
       "3    Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_128x2...         12.0   \n",
       "4    Volta_hmma_implicit_gemm_wgrad_fp32_nhwc_64x32...         24.0   \n",
       "..                                                 ...          ...   \n",
       "110  volta_fp16_s884cudnn_fp16_256x64_ldg8_relu_f2f...          6.0   \n",
       "111  volta_fp16_s884cudnn_fp16_256x64_ldg8_relu_f2f...          6.0   \n",
       "112       volta_fp16_s884gemm_fp16_128x128_ldg8_f2f_nt         36.0   \n",
       "113  volta_fp16_scudnn_fp16_128x64_relu_interior_nn_v1         12.0   \n",
       "114                    volta_fp16_sgemm_fp16_128x32_nt         12.0   \n",
       "\n",
       "    Network Name  Batch Size      Pass Precision  CUDA Time Avg  TC Time Avg  \\\n",
       "0        deepCam           2  backward     mixed       0.000165     0.000165   \n",
       "1        deepCam           2  backward     mixed       0.000120     0.000120   \n",
       "2        deepCam           2  backward     mixed       0.002004     0.002003   \n",
       "3        deepCam           2  backward     mixed       0.002617     0.002624   \n",
       "4        deepCam           2  backward     mixed       0.000211     0.000230   \n",
       "..           ...         ...       ...       ...            ...          ...   \n",
       "110      deepCam           2   forward     mixed       0.000080     0.000080   \n",
       "111      deepCam           2   forward     mixed       0.000303     0.000307   \n",
       "112      deepCam           2   forward     mixed       0.000425     0.000469   \n",
       "113      deepCam           2   forward     mixed       0.000171     0.000000   \n",
       "114      deepCam           2   forward     mixed       0.000301     0.000000   \n",
       "\n",
       "     FP32 FLOPs Avg  FP16 FLOPs Avg  ...  FP16 L2 AI    TC L2 AI      DRAM AI  \\\n",
       "0      3.382784e+06             0.0  ...    0.000000   86.269259   460.004408   \n",
       "1      2.048000e+06             0.0  ...    0.000000  175.980559   411.945348   \n",
       "2      6.930432e+06             0.0  ...    0.000000  421.062825  1362.422104   \n",
       "3      3.538944e+06             0.0  ...    0.000000  133.586092  1491.376331   \n",
       "4      2.347008e+06             0.0  ...    0.000000   30.525030    70.019151   \n",
       "..              ...             ...  ...         ...         ...          ...   \n",
       "110    1.061683e+07        663552.0  ...    0.010521   63.149830   262.910613   \n",
       "111    5.662310e+07       3538944.0  ...    0.010270   57.673099   234.258467   \n",
       "112    5.573837e+07             0.0  ...    0.000000   64.365833   246.901319   \n",
       "113    1.833173e+09             0.0  ...    0.000000    0.000000    30.543450   \n",
       "114    3.630957e+09             0.0  ...    0.000000    0.000000    29.308326   \n",
       "\n",
       "     FP32 DRAM AI  FP16 DRAM AI   TC DRAM AI     SYSMEM AI  FP32 SYSMEM AI  \\\n",
       "0        0.110112      0.000000   459.894296  6.308905e+07    1.510171e+04   \n",
       "1        0.117225      0.000000   411.828123  3.212944e+07    9.142857e+03   \n",
       "2        0.056049      0.000000  1362.366055  7.520624e+08    3.093943e+04   \n",
       "3        0.020842      0.000000  1491.355488  1.130491e+09    1.579886e+04   \n",
       "4        0.017258      0.000000    70.001893  4.251066e+07    1.047771e+04   \n",
       "..            ...           ...          ...           ...             ...   \n",
       "110      0.698876      0.043680   262.168057  1.783014e+07    4.739657e+04   \n",
       "111      0.665453      0.041591   233.551423  8.898636e+07    2.527817e+05   \n",
       "112      0.387155      0.000000   246.514164  1.586883e+08    2.488320e+05   \n",
       "113     30.543450      0.000000     0.000000  8.183808e+06    8.183808e+06   \n",
       "114     29.308326      0.000000     0.000000  1.620963e+07    1.620963e+07   \n",
       "\n",
       "     FP16 SYSMEM AI  TC SYSMEM AI  \n",
       "0          0.000000  6.307394e+07  \n",
       "1          0.000000  3.212029e+07  \n",
       "2          0.000000  7.520315e+08  \n",
       "3          0.000000  1.130475e+09  \n",
       "4          0.000000  4.250018e+07  \n",
       "..              ...           ...  \n",
       "110     2962.285714  1.777978e+07  \n",
       "111    15798.857143  8.871778e+07  \n",
       "112        0.000000  1.584394e+08  \n",
       "113        0.000000  0.000000e+00  \n",
       "114        0.000000  0.000000e+00  \n",
       "\n",
       "[115 rows x 47 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute AI Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum over all kernels\n",
    "combinedselectkeys = [\"Precision\", \"Network Name\", \"Batch Size\", \"Pass\"]\n",
    "\n",
    "#copy profiledf\n",
    "combineddf = profiledf.copy()\n",
    "\n",
    "#get the aggregated performance, including all kernels:\n",
    "#compute weights: multiply all measures by the number of invocations\n",
    "weighted = True\n",
    "if weighted:\n",
    "    #first, get all the names of metrics which need to be weighted\n",
    "    metrics = [x for x in combineddf.columns if \"Avg\" in x]\n",
    "    for metric in metrics:\n",
    "        combineddf[metric] *= combineddf[\"Invocations\"]\n",
    "\n",
    "#sum up\n",
    "combineddf = combineddf.groupby(by=combinedselectkeys).sum()#.reset_index()\n",
    "\n",
    "\n",
    "#the flop fractions need to be recomputed\n",
    "combineddf[\"FP32 FLOPs Fraction Avg\"] = combineddf[\"FP32 FLOPs Avg\"] / combineddf[\"FLOPs Avg\"]\n",
    "combineddf[\"FP16 FLOPs Fraction Avg\"] = combineddf[\"FP16 FLOPs Avg\"] / combineddf[\"FLOPs Avg\"]\n",
    "combineddf[\"TC FLOPs Fraction Avg\"]   = combineddf[\"TC FLOPs Avg\"]   / combineddf[\"FLOPs Avg\"]\n",
    "\n",
    "### Get performance\n",
    "combineddf[\"Performance GFlop/s\"]      = combineddf[\"FLOPs Avg\"]      / (combineddf[\"CUDA Time Avg\"]*10**9)\n",
    "combineddf[\"FP32 Performance GFlop/s\"] = combineddf[\"FP32 FLOPs Avg\"] / (combineddf[\"CUDA Time Avg\"]*10**9)\n",
    "combineddf[\"FP16 Performance GFlop/s\"] = combineddf[\"FP16 FLOPs Avg\"] / (combineddf[\"CUDA Time Avg\"]*10**9)\n",
    "combineddf[\"TC Performance GFlop/s\"]   = combineddf[\"TC FLOPs Avg\"]   / (combineddf[\"TC Time Avg\"]*10**9)\n",
    "\n",
    "\n",
    "### Get AI\n",
    "# L1\n",
    "combineddf[\"L1 AI\"]        = combineddf[\"FLOPs Avg\"]      / combineddf[\"L1 Bytes Avg\"]\n",
    "combineddf[\"FP32 L1 AI\"]   = combineddf[\"FP32 FLOPs Avg\"] / combineddf[\"L1 Bytes Avg\"]\n",
    "combineddf[\"FP16 L1 AI\"]   = combineddf[\"FP16 FLOPs Avg\"] / combineddf[\"L1 Bytes Avg\"]\n",
    "combineddf[\"TC L1 AI\"]     = combineddf[\"TC FLOPs Avg\"]   / combineddf[\"L1 Bytes Avg\"]\n",
    "# L2\n",
    "combineddf[\"L2 AI\"]        = combineddf[\"FLOPs Avg\"]      / combineddf[\"L2 Bytes Avg\"]\n",
    "combineddf[\"FP32 L2 AI\"]   = combineddf[\"FP32 FLOPs Avg\"] / combineddf[\"L2 Bytes Avg\"]\n",
    "combineddf[\"FP16 L2 AI\"]   = combineddf[\"FP16 FLOPs Avg\"] / combineddf[\"L2 Bytes Avg\"]\n",
    "combineddf[\"TC L2 AI\"]     = combineddf[\"TC FLOPs Avg\"]   / combineddf[\"L2 Bytes Avg\"]\n",
    "# DRAM\n",
    "combineddf[\"DRAM AI\"]      = combineddf[\"FLOPs Avg\"]      / combineddf[\"DRAM Bytes Avg\"]\n",
    "combineddf[\"FP32 DRAM AI\"] = combineddf[\"FP32 FLOPs Avg\"] / combineddf[\"DRAM Bytes Avg\"]\n",
    "combineddf[\"FP16 DRAM AI\"] = combineddf[\"FP16 FLOPs Avg\"] / combineddf[\"DRAM Bytes Avg\"]\n",
    "combineddf[\"TC DRAM AI\"]   = combineddf[\"TC FLOPs Avg\"]   / combineddf[\"DRAM Bytes Avg\"]\n",
    "\n",
    "combineddf.sort_values(by=combinedselectkeys).reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricdf.to_csv(\"./metrics.csv\")\n",
    "profiledf.to_csv(\"./profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
